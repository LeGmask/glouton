#
#  Copyright 2015-2016 Bleemeo
#
#  bleemeo.com an infrastructure monitoring solution in the Cloud
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

import distutils.version
import logging
import os
import re
import shlex
import subprocess
import time

import requests
from six.moves import urllib_parse

import bleemeo_agent.util


BASE_TELEGRAF_CONFIG = """# Configuration generated by Bleemeo-agent.
# do NOT modify, it will be overwrite on next agent start.
"""

STATSD_TELEGRAF_CONFIG = """
# Statsd Server
# To disable Statsd server, add:
#     telegraf:
#         statsd_enabled: False
# in /etc/bleemeo/agent.conf.d/99-local.conf
[[inputs.statsd]]
  service_address = "127.0.0.1:8125"
  delete_gauges = false
  delete_counters = false
  delete_timings = true
  percentiles = [90]
  metric_separator = "_"
  allowed_pending_messages = 10000
  percentile_limit = 1000
"""

APACHE_TELEGRAF_CONFIG = """
[[inputs.apache]]
  urls = ["http://%(address)s:%(port)s/server-status?auto"]
"""

DOCKER_TELEGRAF_CONFIG = """
[[inputs.docker]]
    perdevice = false
    total = true
"""

ELASTICSEARCH_TELEGRAF_CONFIG = """
[[inputs.elasticsearch]]
  servers = ["http://%(address)s:%(port)s"]
  local = true
  cluster_health = false
"""

HAPROXY_TELEGRAF_CONFIG = """
[[inputs.haproxy]]
  servers = ["%(stats_url)s"]
"""

MEMCACHED_TELEGRAF_CONFIG = """
[[inputs.memcached]]
  servers = ["%(address)s:%(port)s"]
"""

MONGODB_TELEGRAF_CONFIG = """
[[inputs.mongodb]]
  servers = ["%(address)s:%(port)s"]
"""

MYSQL_TELEGRAF_CONFIG = """
[[inputs.mysql]]
  servers = ["%(username)s:%(password)s@tcp(%(address)s:%(port)s)/"]
"""

NGINX_TELEGRAF_CONFIG = """
[[inputs.nginx]]
  urls = ["http://%(address)s:%(port)s/nginx_status"]
"""

POSTGRESQL_TELEGRAF_CONFIG = """
[[inputs.postgresql]]
    address = "host=%(address)s port=%(port)s user=%(username)s password=%(password)s dbname=postgres sslmode=disable"
"""  # noqa

RABBITMQ_TELEGRAF_CONFIG = """
[[inputs.rabbitmq]]
  url = "http://%(address)s:%(mgmt_port)s"
  username = "%(username)s"
  password = "%(password)s"
"""

REDIS_TELEGRAF_CONFIG = """
[[inputs.redis]]
  servers = ["tcp://%(address)s:%(port)s"]
"""

ZOOKEEPER_CONFIG = """
[[inputs.zookeeper]]
  servers = ["%(address)s:%(port)s"]
"""


def compare_version(current_version, wanted_version):
    """ Return True if current_version is greater or equal to wanted_version
    """
    current_version = distutils.version.LooseVersion(current_version)
    wanted_version = distutils.version.LooseVersion(wanted_version)
    return current_version >= wanted_version


class Telegraf:

    def __init__(self, graphite_server):
        self.core = graphite_server.core
        self.graphite_server = graphite_server

        # used to compute derivated values
        self._raw_value = {}

        self.core.add_scheduled_job(
            self._purge_metrics,
            seconds=5 * 60,
        )

    def _purge_metrics(self):
        """ Remove old metrics from self._raw_value
        """
        now = time.time()
        cutoff = now - 60 * 6

        # XXX: concurrent access with emit_metric
        self._raw_value = {
            key: (timestamp, value)
            for key, (timestamp, value) in self._raw_value.items()
            if timestamp >= cutoff
        }

    def telegraf_version_gte(self, version):
        """ Return True if installed Telegraf version is at least given version

            If unable to compare given version with current version, return
            False (for example fact telegraf_version is absent or any error).
        """
        current_version = self.core.last_facts.get('telegraf_version')
        if current_version is None:
            return False

        try:
            return compare_version(current_version, version)
        except:
            return False

    def update_discovery(self):
        try:
            self._write_config()
        except:
            logging.warning(
                'Failed to write telegraf configuration. '
                'Continuing with current configuration')
            logging.debug('exception is:', exc_info=True)

    def _write_config(self):
        telegraf_config = self._get_telegraf_config()

        telegraf_config_path = self.core.config.get(
            'telegraf.config_file',
            '/etc/telegraf/telegraf.d/bleemeo-generated.conf'
        )

        if os.path.exists(telegraf_config_path):
            with open(telegraf_config_path) as fd:
                current_content = fd.read()

            if telegraf_config == current_content:
                logging.debug('telegraf already configured')
                return

        if (telegraf_config == BASE_TELEGRAF_CONFIG
                and not os.path.exists(telegraf_config_path)):
            logging.debug(
                'telegraf generated config would be empty, skip writting it'
            )
            return

        # Don't simply use open. This file must have limited permission
        # since it may contains password
        open_flags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC
        fileno = os.open(telegraf_config_path, open_flags, 0o600)
        with os.fdopen(fileno, 'w') as fd:
            fd.write(telegraf_config)

        self._restart_telegraf()

    def _get_telegraf_config(self):
        telegraf_config = BASE_TELEGRAF_CONFIG

        if self.core.config.get('telegraf.statsd_enabled', True):
            telegraf_config += STATSD_TELEGRAF_CONFIG

        if self.core.docker_client is not None:
            docker_metrics_enabled = self.core.config.get(
                'telegraf.docker_metrics_enabled', None
            )
            if (docker_metrics_enabled
                    or (
                        docker_metrics_enabled is None
                        and self.telegraf_version_gte('1.0.0')
                    )):
                telegraf_config += DOCKER_TELEGRAF_CONFIG

        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key

            service_info = self.core.services[key].copy()
            service_info['instance'] = instance

            if service_name == 'apache':
                telegraf_config += APACHE_TELEGRAF_CONFIG % service_info
            if service_name == 'elasticsearch':
                telegraf_config += ELASTICSEARCH_TELEGRAF_CONFIG % service_info
            if (service_name == 'haproxy'
                    and service_info.get('stats_url') is not None):
                telegraf_config += HAPROXY_TELEGRAF_CONFIG % service_info
            if service_name == 'memcached':
                telegraf_config += MEMCACHED_TELEGRAF_CONFIG % service_info
            if (service_name == 'mysql'
                    and service_info.get('password') is not None):
                service_info.setdefault('username', 'root')
                telegraf_config += MYSQL_TELEGRAF_CONFIG % service_info
            if service_name == 'mongodb':
                telegraf_config += MONGODB_TELEGRAF_CONFIG % service_info
            if service_name == 'nginx':
                telegraf_config += NGINX_TELEGRAF_CONFIG % service_info
            if (service_name == 'postgresql'
                    and service_info.get('password') is not None):
                service_info.setdefault('username', 'postgres')
                telegraf_config += POSTGRESQL_TELEGRAF_CONFIG % service_info
            if service_name == 'rabbitmq':
                service_info.setdefault('username', 'guest')
                service_info.setdefault('password', 'guest')
                service_info.setdefault('mgmt_port', 15672)
                telegraf_config += RABBITMQ_TELEGRAF_CONFIG % service_info
            if service_name == 'redis':
                telegraf_config += REDIS_TELEGRAF_CONFIG % service_info
            if service_name == 'zookeeper':
                telegraf_config += ZOOKEEPER_CONFIG % service_info

        return telegraf_config

    def _restart_telegraf(self):
        restart_cmd = self.core.config.get(
            'telegraf.restart_command',
            'sudo -n service telegraf restart')
        telegraf_container = self.core.config.get('telegraf.docker_name')
        if telegraf_container is not None:
            bleemeo_agent.util.docker_restart(
                self.core.docker_client, telegraf_container
            )
        else:
            try:
                output = subprocess.check_output(
                    shlex.split(restart_cmd),
                    stderr=subprocess.STDOUT,
                )
                return_code = 0
            except (subprocess.CalledProcessError, OSError) as exception:
                output = exception.output
                return_code = exception.returncode

            if return_code != 0:
                logging.info(
                    'Failed to restart telegraf after reconfiguration: %s',
                    output
                )
            else:
                logging.debug(
                    'telegraf reconfigured and restarted: %s', output)

    def get_derivate(self, name, item, timestamp, value):
        """ Return derivate of a COUNTER (e.g. something that only goes upward)
        """
        (old_timestamp, old_value) = self._raw_value.get(
            (name, item), (None, None)
        )
        self._raw_value[(name, item)] = (timestamp, value)
        if old_timestamp is None:
            return None

        delta = value - old_value
        delta_time = timestamp - old_timestamp

        if delta_time == 0:
            return None

        if delta < 0:
            return None

        return delta / delta_time

    def get_service_instance(self, service, address, port):
        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if (service_name == service
                    and service_info.get('address') == address
                    and service_info.get('port') == port):
                return instance
            # RabbitMQ use mgmt port
            if (service_name == service
                    and service_name == 'rabbitmq'
                    and service_info.get('address') == address
                    and service_info.get('mgmt_port', 15672) == port):
                return instance

        raise KeyError('service not found')

    def get_haproxy_instance(self, hostport):
        if ':' in hostport:
            host, port = hostport.split(':')
            port = int(port)
        else:
            host = hostport
            port = None

        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if service_name != 'haproxy':
                continue
            if 'stats_url' in service_info:
                tmp = urllib_parse.urlparse(service_info['stats_url'])
                if host == tmp.hostname and port == tmp.port:
                    return instance

        raise KeyError('service not found')

    def get_elasticsearch_instance(self, node_id):
        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if service_name != 'elasticsearch':
                continue
            if 'es_node_id' not in service_info:
                try:
                    response = requests.get(
                        'http://%(address)s:%(port)s/_nodes/_local/'
                        % service_info
                    )
                    data = response.json()
                    this_node_id = list(data['nodes'].keys())[0]
                except (requests.RequestException, ValueError):
                    continue

                service_info['es_node_id'] = this_node_id

            if service_info.get('es_node_id') == node_id:
                return instance

        raise KeyError('service not found')

    def docker_container_name(self, part):
        """ Return Docker container name for given graphite line.

            This method does two thing:

            1) Find where the container_name is stored in graphite line
            2) Find the real name of container_name

            For the 2, when sent over graphite protocol, Telegraf replaces
            some char from container_name to "_". This method search which
            container name match the mangled name.

            For the 1, the position on the graphite line of container_name is
            not the same because Telegraf sent all container labels. This
            method find where container_name is based on defined labels for
            each container.

            A container without any labels would only have the following tags:

            host=xenial,container_image=redis,container_name=labeled_redis,
                container_version=unknown,engine_host=docker-host

            Or with older Telegraf (< 1.1.0):

            host=xenial,container_image=redis,container_name=labeled_redis,
                container_version=unknown

            That result in graphite line:

            xenial.redis.labeled_redis.unknown.docker-host

            The version change didn't impact use, as the added
            tag "engine_host", is always after "container_name".

            Here container_name is the 3th position. But if user add a label
            "a_custom_label=my_value", then the graphite line result in:

            xenial.a_custom_label.redis.labeled_redis.unknown

            The container_name is now 4th position.

            In general case, the container_name position is 3 + number of
            label keys that are (in lexical order) before "container_name".
        """

        for container_name, inspect in self.core.docker_containers.items():
            labels = inspect.get('Config', {}).get('Labels', {})
            if labels is None:
                labels = {}
            label_keys_before = [
                key for (key, value) in labels.items()
                if key < 'container_name' and value != ''
            ]
            position = 3 + len(label_keys_before)

            # Docker only allow "_", "." and "-" as special char in
            # container_name. Of those, only "." is replaced by "_"
            tmp = container_name.replace('.', '_')
            if len(part) > position and part[position] == tmp:
                return container_name

        return None

    def emit_metric(
            self, name, timestamp, value, computed_metrics_pending):

        item = None
        service = None
        instance = None
        container_name = None
        derive = False
        no_emit = False

        # name looks like
        # telegraf.HOSTNAME.(ITEM_INFO)*.PLUGIN.METRIC
        # example:
        # telegraf.xps-pierref.ext4./home.disk.total
        # telegraf.xps-pierref.mem.used
        # telegraf.xps-pierref.cpu-total.cpu.usage_steal
        part = name.split('.')

        if part[-2] == 'cpu':
            if part[-3] != 'cpu-total':
                return

            name = part[-1].replace('usage_', 'cpu_')
            if name == 'cpu_irq':
                name = 'cpu_interrupt'
            elif name == 'cpu_iowait':
                name = 'cpu_wait'

            if name == 'cpu_idle':
                self.core.emit_metric({
                    'measurement': 'cpu_used',
                    'time': timestamp,
                    'value': 100 - value,
                })
            computed_metrics_pending.add(('cpu_other', None, None, timestamp))
        elif part[-2] == 'win_cpu':
            if part[2] != '_Total':
                return

            name = part[-1]
            if name == 'Percent_Idle_Time':
                name = 'cpu_idle'
            elif name == 'Percent_Interrupt_Time':
                name = 'cpu_interrupt'
            elif name == 'Percent_User_Time':
                name = 'cpu_user'
            elif name == 'Percent_Privileged_Time':
                name = 'cpu_system'
            elif name == 'Percent_DPC_Time':
                name = 'cpu_softirq'
            else:
                return

            if name == 'cpu_idle':
                self.core.emit_metric({
                    'measurement': 'cpu_used',
                    'time': timestamp,
                    'value': 100 - value,
                })
                computed_metrics_pending.add(
                    ('system_load1', None, None, timestamp)
                )
            computed_metrics_pending.add(('cpu_other', None, None, timestamp))
        elif part[-2] == 'disk':
            path = part[-3].replace('-', '/')
            path = self.graphite_server.disk_path_rename(path)
            if path is None:
                return
            item = path

            name = 'disk_' + part[-1]
            if name == 'disk_used_percent':
                name = 'disk_used_perc'
        elif part[-2] == 'win_disk':
            item = part[2]
            name = part[-1]
            if item == '_Total':
                return

            # For Windows, assimilate disk (which are also named "C:", "D:"...
            # and (mounted) partition like C:
            if self.graphite_server._ignored_disk(item):
                return

            if name == 'Percent_Free_Space':
                name = 'disk_used_perc'
                value = 100 - value

                # when disk_total is processed, disk_used is also emitted
                computed_metrics_pending.add(
                    ('disk_total', item, None, timestamp)
                )
            elif name == 'Free_Megabytes':
                name = 'disk_free'
                value = value * 1024 * 1024
                computed_metrics_pending.add(
                    ('disk_total', item, None, timestamp)
                )
            else:
                return
        elif part[-2] == 'diskio':
            item = part[2]
            name = part[-1]
            if not name.startswith('io_'):
                name = 'io_' + name
            if self.graphite_server._ignored_disk(item):
                return

            if name == 'io_iops_in_progress':
                name = 'io_in_progress'
            else:
                value = self.get_derivate(name, item, timestamp, value)
                if value is None:
                    return

            if name == 'io_time':
                self.core.emit_metric({
                    'measurement': 'io_utilization',
                    # io_time is a number of ms spent doing IO (per seconds)
                    # utilization is 100% when we spent 1000ms during one
                    # second
                    'value': value / 1000. * 100.,
                    'time': timestamp,
                    'item': item,
                })
        elif part[-2] == 'win_diskio':
            item = part[2]
            name = part[-1]
            if item == '_Total':
                return

            # Item looks like "0_C:", "1_D:" or "0_C:_D:" (multiple partition
            # on one disk). Remove the number_ from item and take the smaller
            # letter.
            if '_' in item:
                item_part = item.split('_')
                number = item_part[0]
                try:
                    int(number)
                    item = sorted(item_part[1:])[0]
                except ValueError:
                    pass

            if self.graphite_server._ignored_disk(item):
                return

            if name == 'Disk_Read_Bytes_persec':
                name = 'io_read_bytes'
            elif name == 'Disk_Write_Bytes_persec':
                name = 'io_write_bytes'
            elif name == 'Current_Disk_Queue_Length':
                name = 'io_in_progress'
            elif name == 'Disk_Reads_persec':
                name = 'io_reads'
            elif name == 'Disk_Writes_persec':
                name = 'io_writes'
            elif name == 'Percent_Disk_Time':
                name = 'io_utilization'
                self.core.emit_metric({
                    'measurement': 'io_time',
                    # io_time is a number of ms spent doing IO (per seconds)
                    # utilization is 100% when we spent 1000ms during one
                    # second
                    'value': value * 1000. / 100.,
                    'time': timestamp,
                    'item': item,
                })
            elif name == 'Percent_Disk_Read_Time':
                name = 'io_read_time'
                # Like io_time/io_utilization
                value = value * 1000. / 100.
            elif name == 'Percent_Disk_Write_Time':
                name = 'io_write_time'
                # Like io_time/io_utilization
                value = value * 1000. / 100.
            else:
                return
        elif part[-2] == 'mem':
            name = 'mem_' + part[-1]
            if name in ('mem_used', 'mem_used_percent'):
                # We don't use mem_used of telegraf (which is
                # mem_total - mem_free)
                # We prefere the "collectd one" (which is
                # mem_total - (mem_free + mem_cached + mem_buffered + mem_slab)

                # mem_used will be computed as mem_total - mem_available
                return  # We don't use mem_used of telegraf.
            elif name == 'mem_available_percent':
                name = 'mem_available_perc'
            elif name in ('mem_buffered', 'mem_cached', 'mem_free'):
                pass
            elif name in ('mem_total', 'mem_available'):
                computed_metrics_pending.add(
                    ('mem_used', None, None, timestamp)
                )
            else:
                return
        elif part[-2] == 'win_mem':
            name = part[-1]
            if name == 'Available_Bytes':
                name = 'mem_available'
                self.core.emit_metric({
                    'measurement': 'mem_available_perc',
                    'time': timestamp,
                    'value': value * 100. / self.core.total_memory_size,
                })
                mem_used = self.core.total_memory_size - value
                self.core.emit_metric({
                    'measurement': 'mem_used',
                    'time': timestamp,
                    'value': mem_used,
                })
                self.core.emit_metric({
                    'measurement': 'mem_used_perc',
                    'time': timestamp,
                    'value': mem_used * 100. / self.core.total_memory_size,
                })
                computed_metrics_pending.add(
                    ('mem_free', None, None, timestamp)
                )
            elif name in (
                    'Standby_Cache_Reserve_Bytes',
                    'Standby_Cache_Normal_Priority_Bytes',
                    'Standby_Cache_Core_Bytes'):
                no_emit = True
                computed_metrics_pending.add(
                    ('mem_cached', None, None, timestamp)
                )
            else:
                return
        elif part[-2] == 'net' and part[-3] != 'all':
            item = part[-3]
            if self.graphite_server.network_interface_blacklist(item):
                return

            name = 'net_' + part[-1]
            if name == 'net_bytes_recv' or name == 'net_bytes_sent':
                name = name.replace('bytes', 'bits')
                value = value * 8

            derive = True
        elif part[-2] == 'win_net':
            item = part[2]
            name = part[-1]
            if self.graphite_server.network_interface_blacklist(item):
                return

            if name == 'Bytes_Sent_persec':
                name = 'net_bits_sent'
                value = value * 8
            elif name == 'Bytes_Received_persec':
                name = 'net_bits_recv'
                value = value * 8
            elif name == 'Packets_Sent_persec':
                name = 'net_packets_sent'
            elif name == 'Packets_Received_persec':
                name = 'net_packets_recv'
            elif name == 'Packets_Received_Discarded':
                derive = True
                name = 'net_drop_in'
            elif name == 'Packets_Outbound_Discarded':
                derive = True
                name = 'net_drop_out'
            elif name == 'Packets_Received_Errors':
                derive = True
                name = 'net_err_in'
            elif name == 'Packets_Outbound_Errors':
                derive = True
                name = 'net_err_out'
            else:
                return
        elif part[-2] == 'swap':
            if not self.core.last_facts.get('swap_present', False):
                return
            name = 'swap_' + part[-1]
            if name.endswith('_percent'):
                name = name.replace('_percent', '_perc')
            if name in ('swap_in', 'swap_out'):
                derive = True
        elif part[-2] == 'win_swap':
            if not self.core.last_facts.get('swap_present', False):
                return

            name = part[-1]
            if name == 'Percent_Usage':
                name = 'swap_used_perc'
                if value == 0:
                    swap_used = 0.0
                else:
                    swap_used = self.core.total_swap_size / (value / 100.)
                self.core.emit_metric({
                    'measurement': 'swap_used',
                    'time': timestamp,
                    'value': swap_used,
                })
                self.core.emit_metric({
                    'measurement': 'swap_free',
                    'time': timestamp,
                    'value': self.core.total_swap_size - swap_used,
                })
        elif part[-2] == 'system':
            name = 'system_' + part[-1]
            if name == 'system_uptime':
                name = 'uptime'
            elif name == 'system_n_users':
                name = 'users_logged'
            elif name not in ('system_load1', 'system_load5', 'system_load15'):
                return
        elif part[-2] == 'win_system':
            name = part[-1]
            if name == 'System_Up_Time':
                name = 'uptime'
            elif name == 'Processor_Queue_Length':
                no_emit = True
                computed_metrics_pending.add(
                    ('system_load1', None, None, timestamp)
                )
            else:
                return
        elif part[-2] == 'processes':
            if part[-1] in ['blocked', 'running', 'sleeping',
                            'stopped', 'zombies', 'paging']:
                name = 'process_status_%s' % part[-1]
            elif part[-1] == 'total':
                name = 'process_total'
            else:
                return
        elif part[-2] == 'apache':
            service = 'apache'
            server_address = part[-3].replace('_', '.')
            server_port = int(part[-4])
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'apache_' + part[-1]
            if name == 'apache_IdleWorkers':
                name = 'apache_idle_workers'
            elif name == 'apache_TotalAccesses':
                name = 'apache_requests'
                derive = True
            elif name == 'apache_TotalkBytes':
                name = 'apache_bytes'
                derive = True
            elif name == 'apache_ConnsTotal':
                name = 'apache_connections'
            elif name == 'apache_Uptime':
                name = 'apache_uptime'
            elif 'scboard' in name:
                name = name.replace('scboard', 'scoreboard')
            else:
                return
        elif part[-2] == 'haproxy':
            service = 'haproxy'
            proxy_name = part[2]
            if part[4] not in ('BACKEND', 'FRONTEND'):
                return
            hostport = part[3].replace('_', '.')
            try:
                instance = self.get_haproxy_instance(hostport)
            except KeyError:
                return

            if (part[-1] in ('stot', 'bin', 'bout', 'dreq', 'dresp', 'ereq',
                             'econ', 'eresp', 'req_tot')):
                derive = True
                name = 'haproxy_' + part[-1]
            elif (part[-1] in ('qcur', 'scur', 'qtime', 'ctime', 'rtime',
                               'ttime')):
                name = 'haproxy_' + part[-1]
            elif part[-1] == 'active_servers':
                name = 'haproxy_act'
            else:
                return

            if instance is None:
                item = proxy_name
            else:
                item = instance + '_' + proxy_name
        elif part[-2] == 'memcached':
            service = 'memcached'
            (server_address, server_port) = part[-3].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'memcached_' + part[-1]
            if '_cmd_' in name:
                name = name.replace('_cmd_', '_command_')
                derive = True
            elif name == 'memcached_curr_connections':
                name = 'memcached_connections_current'
            elif name == 'memcached_curr_items':
                name = 'memcached_items_current'
            elif name == 'memcached_bytes_read':
                name = 'memcached_octets_rx'
                derive = True
            elif name == 'memcached_bytes_written':
                name = 'memcached_octets_tx'
                derive = True
            elif name == 'memcached_evictions':
                name = 'memcached_ops_evictions'
                derive = True
            elif name == 'memcached_threads':
                name = 'memcached_ps_count_threads'
            elif name in ('memcached_get_misses', 'memcached_get_hits'):
                name = name.replace('_get_', '_ops_')
                derive = True
            elif name.endswith('_misses') or name.endswith('_hits'):
                name = name.replace('memcached_', 'memcached_ops_')
                derive = True
            elif name != 'memcached_uptime':
                return
        elif part[-2] == 'mysql':
            service = 'mysql'
            (server_address, server_port) = part[-3].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'mysql_' + part[-1]
            derive = True
            if name.startswith('mysql_qcache_'):
                name = name.replace('qcache', 'cache_result_qcache')
                if name == 'mysql_cache_result_qcache_lowmem_prunes':
                    name = 'mysql_cache_result_qcache_prunes'
                elif name == 'mysql_cache_result_qcache_queries_in_cache':
                    name = 'mysql_cache_size_qcache'
                    derive = False
                elif name == 'mysql_cache_result_qcache_total_blocks':
                    name = 'mysql_cache_blocksize_qcache'
                    derive = False
                elif (name == 'mysql_cache_result_qcache_free_blocks'
                        or name == 'mysql_cache_result_qcache_free_memory'):
                    name = name.replace(
                        'mysql_cache_result_qcache_', 'mysql_cache_')
                    derive = False
            elif name.startswith('mysql_table_locks_'):
                name = name.replace('mysql_table_locks_', 'mysql_locks_')
            elif name == 'mysql_bytes_received':
                name = 'mysql_octets_rx'
            elif name == 'mysql_bytes_sent':
                name = 'mysql_octets_tx'
            elif name == 'mysql_threads_created':
                name = 'mysql_total_threads_created'
            elif name.startswith('mysql_threads_'):
                # Other mysql_threads_* name are fine. Accept them unchanged
                derive = False
                pass
            elif name.startswith('mysql_commands_'):
                # mysql_commands_* name are fine. Accept them unchanged
                pass
            elif name.startswith('mysql_handler_'):
                # mysql_handler_* name are fine. Accept them unchanged
                pass
            elif name in ('mysql_queries', 'mysql_slow_queries'):
                pass
            elif name == 'mysql_innodb_row_lock_current_waits':
                derive = False
                name = 'mysql_innodb_locked_transaction'
            else:
                return
        elif part[-2] == 'nginx':
            service = 'nginx'
            server_address = part[-3].replace('_', '.')
            server_port = int(part[-4])
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'nginx_connections_' + part[-1]
            if name == 'nginx_connections_requests':
                name = 'nginx_requests'
                derive = True
            elif name == 'nginx_connections_accepts':
                name = 'nginx_connections_accepted'
                derive = True
            elif name == 'nginx_connections_handled':
                derive = True
        elif part[-2] == 'postgresql':
            service = 'postgresql'
            dbname = part[2]

            if dbname in ('template0', 'template1'):
                return

            connect_string = part[3]
            # connect string look like:
            # "host=172_17_0_4_port=5432_user=bleemeo_user_dbname=postgres"
            match = re.match(
                r'^host=(.*)_port=(.*)_user=.*$',
                connect_string,
            )
            if not match:
                return

            server_address = match.group(1).replace('_', '.')
            server_port = int(match.group(2))
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            derive = True
            if part[-1] == 'xact_commit':
                name = 'postgresql_commit'
            elif part[-1] == 'xact_rollback':
                name = 'postgresql_rollback'
            elif (part[-1] in ('blks_read', 'blks_hit', 'tup_returned',
                               'tup_fetched', 'tup_inserted', 'tup_updated',
                               'tup_deleted', 'temp_files', 'temp_bytes',
                               'blk_read_time', 'blk_write_time')):
                name = 'postgresql_' + part[-1]
            else:
                return

            if instance is None:
                item = dbname
            else:
                item = instance + '_' + dbname
        elif part[-2] == 'redis':
            service = 'redis'

            # Prior to Telegraf 0.13.1, output was
            # telegraf.$HOSTNAME.$PORT.$SERVER.redis.$METRIC
            # Telegraf 0.13.1+, output is
            # telegraf.$HOSTNAME.$PORT.$ROLE.$SERVER.redis.$METRIC

            # Also, for both a $DATABASE may exists just after $HOSTNAME
            # E.g for 0.13.1:
            # telegraf.$HOSTNAME.$DATABASE.$PORT.$ROLE.$SERVER.redis.$METRIC
            #
            # $PORT is part[-4] or part[-5]
            # $SERVER is always part[-3]
            server_address = part[-3].replace('_', '.')
            if part[-4] in ('master', 'slave'):
                server_port = int(part[-5])
            else:
                server_port = int(part[-4])
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'redis_' + part[-1]

            if name == 'redis_clients':
                name = 'redis_current_connections_clients'
            elif name == 'redis_connected_slaves':
                name = 'redis_current_connections_slaves'
            elif name.startswith('redis_used_memory'):
                name = name.replace('redis_used_memory', 'redis_memory')
            elif name == 'redis_total_connections_received':
                name = 'redis_total_connections'
                derive = True
            elif name == 'redis_total_commands_processed':
                name = 'redis_total_operations'
                derive = True
            elif name == 'redis_rdb_changes_since_last_save':
                name = 'redis_volatile_changes'
            elif name in ('redis_evicted_keys', 'redis_keyspace_hits',
                          'redis_keyspace_misses', 'redis_expired_keys'):
                derive = True
            elif name in ('redis_uptime', 'redis_pubsub_patterns',
                          'redis_pubsub_channels', 'redis_keyspace_hitrate'):
                pass
            else:
                return
        elif part[-2] == 'zookeeper':
            service = 'zookeeper'

            # Telegraf 1.0.0 added "state" in tag. Which change position of
            # server_address and server_port.

            # Telegraf <1.0.0, output was:
            # telegraf.$HOSTNAME.$PORT.$SERVER.zookeeper.$METRIC
            # Telegraf 1.0.0+, output is:
            # telegraf.$HOSTNAME.$PORT.$SERVER.$STATE.zookeeper.$METRIC
            server_address = part[3].replace('_', '.')
            server_port = int(part[2])
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'zookeeper_' + part[-1]
            if name.startswith('zookeeper_packets_'):
                derive = True
            elif name in ('zookeeper_ephemerals_count',
                          'zookeeper_watch_count', 'zookeeper_znode_count'):
                pass
            elif name == 'zookeeper_num_alive_connections':
                name = 'zookeeper_connections'
            else:
                return
        elif part[-2] == 'mongodb':
            service = 'mongodb'
            (server_address, server_port) = part[-3].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'mongodb_' + part[-1]
            if name in ('mongodb_open_connections', 'mongodb_queued_reads',
                        'mongodb_queued_writes', 'mongodb_active_reads',
                        'mongodb_active_writes'):
                pass
            elif name == 'mongodb_queries_per_sec':
                name = 'mongodb_queries'
            elif name in ('mongodb_net_out_bytes', 'mongodb_net_in_bytes'):
                derive = True
            else:
                return
        elif part[2] == 'elasticsearch':
            service = 'elasticsearch'
            # It can't rely only on part[3] (node_host), because this is the
            # host as think by ES (usually the "public" IP of the node). But
            # Agent use "127.0.0.1" for localhost.
            # server_address = part[3].replace('_', '.')
            node_id = part[4]
            try:
                instance = self.get_elasticsearch_instance(node_id)
            except KeyError:
                return

            name = None
            if part[-2] == 'elasticsearch_indices':
                if part[-1] == 'docs_count':
                    name = 'elasticsearch_docs_count'
                elif part[-1] == 'store_size_in_bytes':
                    name = 'elasticsearch_size'
                elif part[-1] == 'search_query_total':
                    name = 'elasticsearch_search'
                    derive = True
                    computed_metrics_pending.add(
                        (
                            'elasticsearch_search_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
                elif part[-1] == 'search_query_time_in_millis':
                    name = 'elasticsearch_search_time_total'
                    derive = True
                    no_emit = True
                    computed_metrics_pending.add(
                        (
                            'elasticsearch_search_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
        elif part[-2] == 'rabbitmq_overview':
            service = 'rabbitmq'

            tmp = part[-3]
            if not tmp.startswith('http:--'):
                return  # unknown format
            tmp = tmp[len('http:--'):]
            (server_address, server_port) = tmp.split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self.get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            if part[-1] == 'messages':
                name = 'rabbitmq_messages_count'
            elif part[-1] == 'consumers':
                name = 'rabbitmq_consumers'
            elif part[-1] == 'connections':
                name = 'rabbitmq_connections'
            elif part[-1] == 'queues':
                name = 'rabbitmq_queues'
            elif part[-1] == 'messages_published':
                derive = True
                name = 'rabbitmq_messages_published'
            elif part[-1] == 'messages_delivered':
                derive = True
                name = 'rabbitmq_messages_delivered'
            elif part[-1] == 'messages_acked':
                derive = True
                name = 'rabbitmq_messages_acked'
            elif part[-1] == 'messages_unacked':
                name = 'rabbitmq_messages_unacked_count'
            else:
                return
        elif part[-2] == 'docker':
            if part[-1] == 'n_containers':
                name = 'docker_containers'
            else:
                return
        elif part[-2] == 'docker_container_cpu':
            if part[-1] == 'usage_total':
                name = 'docker_container_cpu_used'
                # Docker sends time in nanosecond. Convert it to seconds
                value = value / 1000000000

                # And return a percentage
                derive = True
                value = value * 100
            else:
                return

            container_name = self.docker_container_name(part)
            if container_name is None:
                return
            item = container_name

            # Only send metric for cpu=cpu-total
            # cpu tag is normally at part[5] position. But any label
            # before "cpu" will change its place
            inspect = self.core.docker_containers[container_name]
            labels = inspect.get('Config', {}).get('Labels', {})
            if labels is None:
                labels = {}
            label_keys_before = [
                key for (key, value) in labels.items()
                if key < 'cpu' and value != ''
            ]
            position = 5 + len(label_keys_before)
            if len(part) <= position or part[position] != 'cpu-total':
                return
        elif part[-2] == 'docker_container_mem':
            if part[-1] == 'usage_percent':
                name = 'docker_container_mem_used_perc'
            elif part[-1] == 'usage':
                name = 'docker_container_mem_used'
            else:
                return

            container_name = self.docker_container_name(part)
            if container_name is None:
                return
            item = container_name
        elif part[-2] == 'docker_container_net':
            if part[-1] == 'rx_bytes':
                name = 'docker_container_net_bits_recv'
                value = value * 8  # Convert bytes => bits
                derive = True
            elif part[-1] == 'tx_bytes':
                name = 'docker_container_net_bits_sent'
                value = value * 8  # Convert bytes => bits
                derive = True
            else:
                return

            container_name = self.docker_container_name(part)
            if container_name is None:
                return
            item = container_name

            # Only send metric for network=total
            # network tag is normally at part[-3] position. But any label
            # after "network" will change its place
            # Note: unlike "device" (for blkio) or "container_name" (for
            # docker_container_name), here we use offset from the end & label
            # *AFTER*, because Telegraf 1.1.0 introduced a new "engine_host"
            # tag. For "device" and "container_name", "engine_host" is AFTER.
            # Here "engine_host" is BEFORE "network". Using this allow same
            # code for all version of Telegraf.
            inspect = self.core.docker_containers[container_name]
            labels = inspect.get('Config', {}).get('Labels', {})
            if labels is None:
                labels = {}
            label_keys_after = [
                key for (key, value) in labels.items()
                if key > 'network' and value != ''
            ]
            position = 3 + len(label_keys_after)
            if len(part) <= position or part[-position] != 'total':
                return
        elif part[-2] == 'docker_container_blkio':
            if part[-1] == 'io_service_bytes_recursive_read':
                name = 'docker_container_io_read_bytes'
                derive = True
            elif part[-1] == 'io_service_bytes_recursive_write':
                name = 'docker_container_io_write_bytes'
                derive = True
            else:
                return

            container_name = self.docker_container_name(part)
            if container_name is None:
                return
            item = container_name

            # Only send metric for device=total
            # device tag is normally at part[5] position. But any label
            # before "device" will change its place
            inspect = self.core.docker_containers[container_name]
            labels = inspect.get('Config', {}).get('Labels', {})
            if labels is None:
                labels = {}
            label_keys_before = [
                key for (key, value) in labels.items()
                if key < 'device' and value != ''
            ]
            position = 5 + len(label_keys_before)
            if len(part) <= position or part[position] != 'total':
                print(part)
                return
        elif (part[2] == 'counter'
                and self.core.config.get('telegraf.statsd_enabled', True)):
            # statsd counter
            derive = True
            name = 'statsd_' + part[3]
        elif (part[2] == 'gauge'
                and self.core.config.get('telegraf.statsd_enabled', True)):
            # statsd gauge
            name = 'statsd_' + part[3]
        elif (part[2] == 'timing'
                and self.core.config.get('telegraf.statsd_enabled', True)):
            # statsd timing
            name = 'statsd_' + part[3] + '_' + part[4]
            if part[4] == 'count':
                # count for timing are number of item per 10 seconds.
                # We want a count per second.
                value = value / 10
        else:
            return

        if name is None:
            return

        if item is None and service is not None:
            item = instance

        if derive:
            value = self.get_derivate(name, item, timestamp, value)
            if value is None:
                return
        metric = {
            'measurement': name,
            'time': timestamp,
            'value': value,
        }
        if service is not None:
            metric['service'] = service
            metric['instance'] = instance
        if item is not None:
            metric['item'] = item
        if container_name is not None:
            metric['container'] = container_name

        self.core.emit_metric(metric, no_emit=no_emit)
